import streamlit as st
import pandas as pd
import yfinance as yf
import requests
from datetime import datetime
import time

# --- 1. CONFIGURATION ---
st.set_page_config(page_title="Momentum 500 - √âtape 3 (Finale)", layout="wide")

# --- 2. SIDEBAR ---
st.sidebar.header("‚öôÔ∏è Param√®tres")
num_assets = st.sidebar.slider("Nombre d'actions √† d√©tenir", 1, 20, 10)
lookback_months = st.sidebar.slider("P√©riode d'analyse Momentum (mois)", 1, 12, 6)
rotation_freq = st.sidebar.slider("Fr√©quence de rotation (mois)", 1, 12, 3)
fees_pct = st.sidebar.slider("Frais par transaction (%)", 0.0, 0.5, 0.10, step=0.01) / 100

st.sidebar.markdown("---")
# Utilisation d'un s√©lecteur de date pour √©viter les erreurs de frappe
start_date = st.sidebar.date_input("Date de d√©but", datetime(1980, 1, 1))
end_date = st.sidebar.date_input("Date de fin", datetime.now())

# --- 3. FONCTIONS DE R√âCUP√âRATION ---

@st.cache_data
def get_sp500_tickers():
    url = 'https://en.wikipedia.org/wiki/List_of_S%26P_500_companies'
    headers = {'User-Agent': 'Mozilla/5.0'}
    response = requests.get(url, headers=headers)
    df = pd.read_html(response.text)[0]
    return df['Symbol'].str.replace('.', '-', regex=True).tolist()

def fetch_safe(tickers, start, end, column="Close"):
    """T√©l√©chargement ultra-s√©curis√© par paquets de 10"""
    all_data = []
    chunk_size = 10 
    ticker_chunks = [tickers[i:i + chunk_size] for i in range(0, len(tickers), chunk_size)]
    
    pbar = st.progress(0.0)
    msg = st.empty()
    
    for i, chunk in enumerate(ticker_chunks):
        msg.text(f"üì• {column} : Paquet {i+1}/{len(ticker_chunks)}")
        try:
            # T√©l√©chargement avec timeout court
            data = yf.download(chunk, start=start, end=end, interval="1mo", progress=False, group_by='column')[column]
            if not data.empty:
                # Si une seule action est retourn√©e, c'est une Series, on la convertit en DataFrame
                if isinstance(data, pd.Series):
                    data = data.to_frame()
                all_data.append(data)
            
            # Pause de s√©curit√© pour √©viter le blocage IP
            time.sleep(0.3)
        except Exception:
            continue # On ignore les erreurs individuelles de paquets
        
        pbar.progress((i + 1) / len(ticker_chunks))
    
    if not all_data:
        return pd.DataFrame()
    
    # Fusion en √©liminant les doublons potentiels
    return pd.concat(all_data, axis=1).sort_index()

# --- 4. EX√âCUTION ---
st.title("üöÄ Momentum 500 : √âtape 3 (Mode Survie)")
st.warning("‚ö†Ô∏è Attention : Remonter √† 1980 avec 500 actions est tr√®s lourd. Si cela √©choue encore, essayez de mettre 2000/01/01 comme date de d√©but.")

tickers = get_sp500_tickers()

if st.button("Lancer le chargement haute s√©curit√©"):
    # Nettoyage des dates pour Yahoo
    s_str = start_date.strftime('%Y-%m-%d')
    e_str = end_date.strftime('%Y-%m-%d')
    
    # 1. Indice
    with st.spinner("Indice..."):
        mkt = yf.download("^GSPC", start=s_str, end=e_str, interval="1mo", progress=False)
    
    # 2. Cl√¥tures
    closes = fetch_safe(tickers, s_str, e_str, "Close")
    
    # 3. Ouvertures
    opens = fetch_safe(tickers, s_str, e_str, "Open")
    
    if not closes.empty and not opens.empty:
        # On ne garde que les tickers pr√©sents dans les deux fichiers
        common_cols = closes.columns.intersection(opens.columns)
        closes = closes[common_cols]
        opens = opens[common_cols]
        
        st.success(f"‚úÖ Analyse possible sur {len(common_cols)} actions.")
        
        st.session_state['closes'] = closes
        st.session_state['opens'] = opens
        st.session_state['mkt'] = mkt
        
        st.write("**Derni√®res lignes des Cl√¥tures :**")
        st.dataframe(closes.tail(3))
    else:
        st.error("√âchec partiel ou total. Veuillez r√©duire la p√©riode (ex: 1990 ou 2000).")

elif 'closes' in st.session_state:
    st.success("Donn√©es pr√™tes en m√©moire.")
